---
title: "HW 5 - Species Distribution Modeling"
date: "Due Tuesday, October 8th, 2024 via GitHub"
output: pdf_document
geometry: top=1in, bottom=1in, left=1in, right=1in
---

***  
```{r Libraries}
library(dplyr)
library(dismo)
library(ecospat)
library(ENMeval)
library(geodata)
library(ggplot2)
library(ggspatial)
library(gstat)
library(raster)
library(ncf)
library(patchwork)
library(predicts)
library(terra)   
library(readr)
library(rJava)
library(sf) 
library(sp)
library(spatstat.data)
library(spatstat)
library(terra)
library(usdm)
library(viridis)
```

Assignment: Like many analyses in spatial ecology, working with SDMs requires that you develop skills to prepare the necessary spatial data sets. In this coding assignment, we will be fitting SDMs to our old friend the Austral grass tree (Xanthorrhoea australis). 
To do so, we will need to assemble two data sets:
(1) species occurrence records and 
(2) environmental rasters. 
Luckily, you already ahve some practice completing theses tasks. You will first dowload and prepare bioclimatic rasters as in coding assignment #2. You will then download and prepare a thoroughly cleaned set of occurrence records for X. australis. For these steps, be sure to refer back to your coding assignment #2 submission as well as the solution. After creating a set of background (pseudo-absence) data, will divide the occurrence data into a training set (for model fitting) and a testing set (for model evaluation) and will check our candidate variables for potential issues with collinearity, removing any variables that are problematic before fitting models.

Data ‘cleaning’ is always important and especially so for data downloaded from online biodiversity databases such as GBIF. Data cleaning typically involves removing duplicates, erroneous records (i.e., records with wrong geographic coordinates, outside of the native range of the species, low spatial precision, etc.). The goal is to produce a data set that is appropriate for (1) fitting SDMs (i.e., to avoid the old modeling adage: ‘garbage in, garbage out’) and (2) your particular research objective. One important step in the data cleaning process is plotting your data to make sure everything overlaps correctly in geographic space and generally makes sense given what (if anything) you know about the species. Again, refer to the solution to coding assignment #2 to make sure your code works correctly. You will be graded on your ability to produce clean, well commented R code that performs the tasks listed below without error. When you are done, push your code to GitHub and submit an issue so I know you have completed the assignment.


```{r Use the geodata package to download bioclimatic variables from the Worldclim (https://www.worldclim.org/) climate data set at 5 arc-minute resolution. Note that unfortunately, we can’t use the worldclim_country function to download data for only Australia, because, for some reason, that function only provides data at 1km x 1km resolution!}
# Download bioclimatic variables at 5 arc-minute resolution (bummer about the worldclim_country bit, though)
bioclim_data <- worldclim_global(var = "bio", res = 5, path = "C:/Users/Ray.Mroch.NMFS/Documents/Research/Coursework/MEES 698C Spatial Ecology/HW1/HW1")

#check it out
plot(bioclim_data)

# download the bioclim variables
bioRasts <- worldclim_global(var="bio", res=5, path=getwd())
names(bioRasts) <- paste0("bio", 1:19)
#plot bio_1 to have a look at the data
plot(bioRasts[[1]])

# check the CRS of the rasters
terra::crs(bioRasts, describe=T)

# rename the layers for convenience
names(bioRasts) <- paste0("bio", 1:19)

```

2. In coding assignment #2, we worked with four of the bioclimatic variables. Here, we want to consider more candidate variables for species distribution modeling:

```{r setup 2, part 1: cropping raster stack}
## Modify the raster stack of the 19 bioclim variables downloaded in step #1 to produce a new stack that contains bios 2-7, 10, 11, 15, 18, and 19 (put another way, the stack should exclude bio1, bio8, bio9, bio12, bio13, bio14, bio16, and bio17).
# stack layers 2-7, 10, 11, 15, 18, and 19

#####Easier way to do this would be: (THANKS! That is easier)
bioclim_stack <- bioRasts[[c(2, 3, 4, 5, 6, 7, 10, 11, 15, 18, 19)]]
#name them something easier
names(bioclim_stack) <- c("bio2", "bio3", "bio4", "bio5", "bio6", "bio7", "bio10", "bio11", "bio15", "bio18", "bio19")
#check
head(bioclim_stack)
#all NAs, check again
tail(bioclim_stack) #<-OK, there are some numbers in it.

# Crop the resulting raster stack to the outline of Australia (not the extent) using the shapefile provided with coding assignment #2. Rename the cropped rasters so they have the correct names (e.g., bio2, bio3, etc.).
# Stralya shapefile, mate! ... um, but it contains Kiwi crap, too
ausNZ <- vect("C:/Users/Ray.Mroch.NMFS/Documents/Research/Coursework/MEES 698C Spatial Ecology/HW1/oz_nz_aea.shp")

# check CRS of the shapefile, differs from bioRasts!
crs(ausNZ, describe = T)

# remove New Zealand
aus.albers <- subset(ausNZ, ausNZ$NAME == "Australia")
#convert to wgs84
aus.wgs84 <- project(aus.albers, crs("+proj=longlat +datum=WGS84 +no_defs"))
# Check the CRS to ensure it's correct
print(crs(aus.wgs84))

# crop the raster stack to the outline of Australia
bioRasts.aus <- crop(bioRasts, aus.wgs84, mask = TRUE)

# plot the cropped raster stack
plot(bioRasts.aus)
```

3. Use the geodata package to download records for the Austral grass tree (Xanthorrhoea australis). Once downloaded from GBIF, clean the resulting data frame by removing records that:
• Do not have geographic coordinates
• Fall outside the native range of the species (southeast corner of Australia only)
• Do not overlap the bioclimatic rasters
• Have coordinate uncertainty greater than 10 km
• Were collected before 1990
• Are duplicated
• Are gridded spatial duplicates
As we have discussed in class, gridded spatial duplicates are observations that are close enough in geographic space such that they fall in the same raster grid cell, so spatial duplication depends on the resolution of the raster data. There are some exceptions, but in most cases, we do not want to fit a model using spatial duplicates.
```{r setup 3}
# download the species occurrence data
xanth <- sp_occurrence(genus = "Xanthorrhoea",
                         species = "australis",
                         download = T,
                         geo = T, #indicates that there shoudl be none without coordinates!
                         removeZeros = T)

# select points that fall within the Australia polygon
xanth.sf <- st_as_sf(xanth, coords = c("lon", "lat"), crs = 4326)
dim(xanth.sf)#<6732 (still)
#australia shape file
aus.sf <- st_as_sf(aus.wgs84)
#remove non-aus records
xanth.aus.sf <- st_intersection(xanth.sf, aus.sf)
#check to see how many
dim(xanth.aus.sf)#6599 now
#plot to check
ggplot() +
  geom_sf(data = aus.sf) +
  geom_sf(data = xanth.aus.sf, aes(color = acceptedScientificName)) + #<- OK, Uluru xanth removed
  theme_minimal()

#back to data frame for more cleaning
xanth.aus <- as.data.frame(xanth.aus.sf)

#remove those that: Do not have geographic coordinates
#Remove records without geographic coordinates (lat/lon)
xanth_cleaned <- xanth.aus %>%
  filter(!is.na(geometry)) 
dim(xanth_cleaned)# 6599 seems that there were no NAs
xanth.clean.sf <- st_as_sf(xanth_cleaned)
#remove those that: Fall outside the native range of the species (southeast corner of Australia only)
xanth.aus.sf <- sf::st_intersection(xanth.clean.sf, aus.sf) #<- now no out-of-australia sites, but still a weird one on Uluru or something
plot(xanth.aus.sf)
dim(xanth.aus.sf)
# find the westernmost record
west <- which.min(data.frame(st_coordinates(xanth.aus.sf))$X)

# remove the westernmost record
xanth.clean.sf <- xanth.aus.sf[-west,]
dim(xanth.clean.sf)#-1, let's plot again
#plot to check
ggplot() +
  geom_sf(data = aus.sf) +
  geom_sf(data = xanth.clean.sf, aes(color = acceptedScientificName)) + #<- OK, Uluru xanth removed
  theme_minimal()
#back to data frame
xanth_cleaned <- as.data.frame(xanth.clean.sf)
dim(xanth_cleaned)
#remove those that: Do not overlap the bioclimatic rasters
#I an struggling with this one, since they're all both already in Australia, shouldn't this be done?

#####
#####

#remove those that: Have coordinate uncertainty greater than 10 km
xanth_cleaned <- xanth_cleaned %>%
  filter(is.na(coordinateUncertaintyInMeters) | coordinateUncertaintyInMeters <= 10000)

dim(xanth_cleaned) #6554 obs now
#remove those that: Were collected before 1990
summary(xanth_cleaned$year) #wow, going back to 1770, Ned Kelly may be in there
#check to see what is going on with this
year_counts <- as.data.frame(xanth_cleaned %>%
  group_by(year) %>%
  summarize(count = n())) #a few NA years, maybe we should clean them
sum(year_counts$count[year_counts$year >= 1990], na.rm = TRUE)
#4583 should be what is left
xanth_cleaned <- xanth_cleaned %>%
  filter(year >= 1990)
dim(xanth_cleaned) #4583 now

#remove those that: Are duplicated
xanth_cleaned <- xanth_cleaned %>%
  distinct(geometry, .keep_all = TRUE)
dim(xanth_cleaned) #3700 now

#remove those that: Are gridded spatial duplicates
xanth_cleaned <- xanth_cleaned %>%
  mutate(rounded_longitude = round(st_coordinates(geometry)[, 1], 3),
         rounded_latitude = round(st_coordinates(geometry)[, 2], 3)) %>%
  filter(!duplicated(paste(rounded_longitude, rounded_latitude)))
dim(xanth_cleaned) #3077 now, but this is a much smaller resolution than the data are in (5 arc-minutes)

xanth_cleaned <- xanth_cleaned %>%
  mutate(rounded_longitude = round(st_coordinates(geometry)[, 1] / (1/12)) * (1/12), #5 arc-minutes are 1/12 of an hour
         rounded_latitude = round(st_coordinates(geometry)[, 2] / (1/12)) * (1/12)) %>% #same as previous line
  filter(!duplicated(paste(rounded_longitude, rounded_latitude)))
dim(xanth_cleaned) #593 now, seems good


#plot to check
#convert to sf
# Extract coordinates from the geometry column
coords <- st_coordinates(xanth_cleaned$geometry)

# Plot the occurrence points on top of the raster
plot(bioRasts.aus[[3]], main = "Bioclimatic Variable with Xanthorrhoea australis Points")
points(coords, col = 'blue', pch = 19, cex = 0.7)
#OK, I think this looks alright
```
QUESTION 1: In general terms, how would you expect the resolution of a raster to influence the number of spatial duplicates?
  There would be an inverse relationship between the precision of the raster resolution and the number of spatial duplicates. With a low resolution, each raster pixel would have a larger area, increasing the likelihood of spatial duplicates, this would be reversed with a higher resolution in all cases, since the raster pixel would be smaller and leave less room for spatial duplicates.

At the end of step #3, you should have a cleaned point occurrence data set with the correct CRS. Be sure to plot your data to check if everything seems OK. I ended up with about 500 points post-cleaning. Your result should be close to this number.  

After Step #3, you should have (1) a prepared set of bioclimatic rasters and (2) cleaned presence-only occurrence records. We need to do a few more things before we are ready to fit and evaluate models. We will be fitting two presence-only SDM methods (Mahalanobis and Maxent). However, our evaluation metrics require absence data and so we will need to generate background points (pseudo-absences) and divide the occurrence data into training and testing sets for the model fitting and evaluation. We also will need to remove highly correlated variables before fitting models.
```{r }
#reminder, here are the bioclim rasters
bioRasts.aus
# Ensure occurrence data is in the correct CRS and format
xanth.clean.sf <- st_as_sf(xanth_cleaned)
dim(xanth.clean.sf) #this is the cleaned dataset.

# 4. Use your cleaned point occurrence data to extract the bioclimatic variables from the raster stack.
bio_values <- terra::extract(bioRasts.aus, vect(xanth.clean.sf))
bioclim.xanth.clean <- cbind(xanth.clean.sf, bio_values)
#5. Generate a set of 10,000 background points and extract the bioclimatic variables from the raster stack. Combine the resulting tabel with the table produced in Step #4.
set.seed(234)
#10k random background points
envBg <- spatSample(bioRasts.aus, size = 10000, 
#^env(vironmental)B(ack)G(round)  method = 'random',
                                  na.rm = TRUE,
                                  cells = T,
                                  xy = TRUE)

#vector of occurrence (1 for presence, 0 for absence)
bvOcc <- as.data.frame(c(rep(1,nrow(bioclim.xanth.clean)), rep(0, nrow(envBg))))

# x-y columns from each, needs to be a matrix
xyPres <- as.matrix(st_coordinates(bioclim.xanth.clean$geometry)) #593
#colnames capitalized for some reason
colnames(xyPres) <- c("x", "y")
xyBg <- cbind(envBg$x, envBg$y) #10k
colnames(xyBg) <- c("x", "y")
xybgcoord <- as.data.frame(coordinates(xyBg))
#select environmental columns (bio1-19) based on the names (REMEMBER TO USE THE ONE THAT WE JUST Cbound)
envPres.x <- bioclim.xanth.clean[, names(bioRasts.aus)]
envBg.x <- st_as_sf(envBg, coords = c("x", "y"), crs = 4326)
# not sure why I got so many columns so ...
# Subset envPres.x by names in envBg.x
common_vars <- intersect(names(envPres.x), names(envBg.x))
envPres.x <- envPres.x[, common_vars]
envBg.x <- envBg.x[, common_vars]
#now make a data.frame
sdmData <- data.frame(cbind(rbind(xyPres, xyBg), #coords
                            bvOcc,#presence
                            rbind(envPres.x, envBg.x))) #environmental data
head(sdmData)
summary(sdmData)
colnames(sdmData) <- c("x", "y", "pres", "bio1" , "bio2" , "bio3" , "bio4" , "bio5" , "bio6" , "bio7" , "bio8" , "bio9" , "bio10" , "bio11" , "bio12" , "bio13" , "bio14" , "bio15" , "bio16" , "bio17", "bio18", "bio19", "geometry")
sdmdata_noxy <- sdmData %>% select(-geometry)
#6. Use the vifstep function in the usdm library to remove highly correlated variables from your data table. You will use the remaining variables to fit SDMs. I ended up with 6 uncorrelated bioclimatic variables.
#variance inflation factor test (VIF)
VIF <- vifstep(sdmdata_noxy, th = 5) #this will show the VIF with less than 5
#clean up the rasters for later
bioRasts.aus.clean <- subset(bioRasts.aus, c("bio2", "bio3", "bio8", "bio9", "bio18", "bio19"))
#show the results
print(VIF)
#remove those with high multicollinearity
sdmData_clean <- sdmData[, !names(sdmData) %in% c("bio14", "bio15", "bio18", "bio19")]
dim(sdmData_clean) #removed 4 variables

#colname is kind of clunky
colnames(sdmData_clean) <- c("x", "y", "pres", "bio1" , "bio2" , "bio3" , "bio4" , "bio5" , "bio6" , "bio7" , "bio8" , "bio9" , "bio10" , "bio11" , "bio12" , "bio13" , "bio16" , "bio17")
#7. Divide the occurrence data into 80% training and 20% testing partitions using the ENMeval::get.randomkfold function.
#set seed for replicability
set.seed(234)

bv.kfold <- ENMeval::get.randomkfold(occs=subset(sdmData, bvOcc == 1),
                      bg=subset(sdmData, bvOcc == 0),
                      k=5) #5 random folds (80/20)
#check it out
str(bv.kfold)
table(bv.kfold$occs.grp)
#8. Make a map showing the training and testing presences and background points as different symbols plotted on top of one of the bioclimatic rasters.
# Create a new grouping variable
pts.grp <- ifelse(bv.kfold$occs.grp == 1, "test", "train")
#evaluate the plot
evalplot.grps(pts=xyPres, 
              pts.grp=pts.grp,
              envs=stack(bioRasts.aus[[19]])) #bio19 because it's best
# make life a little easier
selTrainTest <- as.numeric(unlist(bv.kfold))

# create a training dataset by picking all but one of the folds
sdmData.train <- subset(sdmData, selTrainTest != 1)
dim(sdmData.train)
# create a testing dataset by reserving the last fold
sdmData.test <- subset(sdmData, selTrainTest <= 1)
dim(sdmData.test)

# make sf versions for plotting
sdmData.train.sf <- st_as_sf(sdmData.train, coords = c("x", "y"), crs=4326)
sdmData.test.sf <- st_as_sf(sdmData.test, coords = c("x", "y"), crs=4326)
#need coordinates of positives
coordspres <- as.matrix(cbind(sdmData_clean$x, sdmData_clean$y))
colnames(coordspres) <- c("x","y")


#9. Use your training data and the uncorrelated set of bioclimatic rasters to fit and predict a Mahalanobis model (using the mahal function in dismo). Note that mahal predictions are slow, so it may take a few minutes to complete the prediction.

# Fit Mahalanobis model
#run the mahalanobis model
mahal_model <- mahal(stack(bioRasts.aus.clean), #< this is a raster stack of the ones that were VIF-ed out: see print(VIF)
                     xyPres) #< this is just X-Y of presence points.
#10. Make a map of the prediction. The predictions from mahal are 1-distance, so we will need to convert the distance predictions from the mahal function to a probability. Here is some R code to do that - it takes as input (1) a raster of the raw prediction (called mahalPred in the code below) from the predict function and the stack of rasters used to fit the model (called bioRastsKeep in the code below).
# Make predictions using the model and the environmental raster stack
mahalPred <- predict(bioRasts.aus.clean, mahal_model)
# Convert distances to a p-value
mm.prob <- app(mahalPred, function(x, k=nlyr(bioRasts.aus.clean)){
x <- 1-x
x <- x^2
p_value <- pchisq(x, df = k, lower.tail = FALSE)
return(p_value)
})
mm.prob_df <- as.data.frame(mm.prob, xy = TRUE)
#spatraster didn't work, converting to df
ggplot(data = mm.prob_df, aes(x = x, y = y, fill = lyr.1)) + 
  geom_raster() +
  scale_fill_gradientn(colors = brewer.pal(9, "YlOrRd"), na.value = "transparent", name = "Prob") +
  theme_minimal()
#cool! They look like they could exist somewhere else, someone's not realizing their whole fundamental niche ...
# evaluate the model (presences + background)
?predicts::pa_evaluate
predAtTrain <- terra::extract(mm.prob, sdmData.train[sdmData.train$pres==1,c("x","y")])$lyr.1
predAtTest <- terra::extract(mm.prob, sdmData.test[sdmData.test$pres==1,c("x","y")])$lyr.1
predAtBg <- terra::extract(mm.prob, sdmData.train[sdmData.train$pres==0,c("x","y")])$lyr.1

# evaluate using training data
evalTrain <- predicts::pa_evaluate(p=predAtTrain, # presences
              a=predAtBg) # background / absences
evalTrain

# evaluate using test data
evalTest <- predicts::pa_evaluate(p=predAtTest, # presences
              a=predAtBg) # background / absences
evalTest

# let's check model quality using the Boyce Index
boyceTrain <- ecospat::ecospat.boyce(mm.prob, obs=sdmData.train[sdmData.train$pres==1,c("x","y")])
boyceTrain

boyceTest <- ecospat::ecospat.boyce(mm.prob, obs=sdmData.test[sdmData.test$pres==1,c("x","y")])
boyceTest

# AUC-PR
prTrain <- PRROC::pr.curve(scores.class0 = predAtTrain, 
                    scores.class1 = predAtBg, 
                    curve = TRUE)
prTrain

prTest <- PRROC::pr.curve(scores.class0 = predAtTest, 
                   scores.class1 = predAtBg, 
                   curve = TRUE)
prTest

# To plot the PR curve
plot(prTrain)
plot(prTest)
```

```{r maxent}
#11. Use your training data and the uncorrelated set of bioclimatic rasters to fit and predict a MaxEnt model using predicts::MaxEnt. Use jackknifing to assess variable importance and produce plots of variable response curves. Make a map of the prediction. Model fitting could take a moment or two.
# Example: Ensure raster stack and presence points are prepared
bioRastsKeep <- stack(bioRasts.aus.clean)  # Uncorrelated set of bioclimatic rasters
bioRastsKeep_brick <- brick(bioRastsKeep)
filepath <- "C:/Users/Ray.Mroch.NMFS/Documents/Research/Coursework/MEES 698C Spatial Ecology/HW1/HW1/maxent"
sdmdata.posloc <- as.data.frame(sdmData_clean[sdmData_clean$pres==1, c("x","y")])
# Fit MaxEnt model
mx <- maxent(
    x = stack(bioRastsKeep),  # env data as a raster stack
    p = sdmData.train[sdmData.train$pres == 1, c("x", "y")],  # presence data
    a = sdmData.train[sdmData.train$pres == 0, c("x", "y")],  # background data
    path = filepath,  # where to save all the output
    args = c("responsecurves","jackknife", "replicates=5")
)


plot(mx)
mx
# predict back to geography
mxPred <- predict(mx, bioRastsKeep)
plot(mxPred, col=rgb.tables(1000))
```

QUESTION 2: According to your maxent model, which are the two most important variables associated with the distribution of the Austral grass tree? Which variable is least important?
  According to the Maxent output Bio19 (Coldest quarter precipitation) is the most important contributing 82.2% of the variation, followed by Bio18 (Warmest quarter precipitation) with 8.7% of it. The Bio3 (isothermality) variable contributed least of the models tested with 1% contribution. So, it would seem that water is important to this organism overall.

QUESTION 3: Based on your interpretation of the response curves, what can you say about bioclimatic controls on the distribution of the Austral grass tree?
  Bio19, the coldest quarter, has a relatively narrow habitat ragne along the spectrum of observations tested, it seems to have an abrupt dropoff (probably near a frost damage threshhold) at the lower end, but it tapers off towards the higher end of the figure. Bio18, the warmest quarter variable, has most observations at the low end, but a slow and steady tapering as temperatures increase. So, I would hypothesize that this plant is sensitive to cold/frost, but increasingly intolerant to warmth along its habitat range. 

QUESTION 4: Compare the predicted distributions from the two SDMs. How are they similar / different? Where do the models over- or under-predict the distribution? What might account for these model “errors”?
  Both models are generally similar in their predictions. There are high probabilities in Tasmania and Southeastern Australia, with little exclaves in Southwestern Australia where the habitat is suitable, but ostensibly have not been colonized or had seed dispersal opportunities there. The Mahalanobis model has a more favorable overall outlook for its predictions. It predicts a greater overall range of habitat suitability and a higher probability of occurrence where it is positive. As mentioned, these models overpredict the presence in Southwestern Australia. This may account for other factors, the aforementioned lack of dispersal opportunities or maybe they're tasty to rabbits and that is on the otehr side of the rabbit-proof fence.

```{r maxent evaluation}
#12. Evaluate the mahal and maxent models using the testing data.
# evaluate the model
predAtTrain <- raster::extract(mxPred, sdmData.train[sdmData.train$pres == 1, c("x", "y")])
predAtTest <- terra::extract(mxPred, sdmData.test[sdmData.test$pres == 1 , c("x","y")])
predAtBg <- terra::extract(mxPred, sdmData.train[sdmData.train$pres == 0 , c("x","y")])

# evaluate using training data
evalTrain <- pa_evaluate(p=predAtTrain, # presences
                         a=predAtBg) # background / absences
evalTrain

# evaluate using test data
evalTest <- pa_evaluate(p=predAtTest, # presences
                        a=predAtBg) # background / absences
evalTest

# let's check model quality using the Boyce Index

#boyce needs rasterstack
mxPredStack<- stack(mxPred)
#boyce also needs presence points(pp)
pptrain <- sdmData.train[sdmData.train$pres == 1, c("x", "y")]
pptest <- sdmData.train[sdmData.test$pres == 1, c("x", "y")]

boyceTrain <- ecospat.boyce(mxPredStack, obs = pptrain)

boyceTrain <- ecospat.boyce(mxPredStack, obs = pptest)
boyceTrain

boyceTest <- ecospat.boyce(mxPred, obs=sdmData.test[sdmData.train$pres==1,c("x","y")])
boyceTest

# AUC-PR
prTrain <- pr.curve(scores.class0 = predAtTrain, 
                    scores.class1 = predAtBg, 
                    curve = TRUE)
prTrain

prTest <- pr.curve(scores.class0 = predAtTest, 
                   scores.class1 = predAtBg, 
                   curve = TRUE)
prTest

# To plot the PR curve
plot(prTrain)
plot(prTest)
```

QUESTION 5: Briefly discuss the model evaluation metrics. Which model performed best? My AUC values for these models were quite similar even though their predictions were not. If you were a conservation manager and were provided output from these two models, how might you handle this seeming contradiction between the differences in the spatial predictions, but similarity in AUC?
  There was a high AUC (.981) for the maxent model indicating a good fit, but there was a pretty low correlation between observations and predictions. This could be fine, but it could indicate that there are more considerations to think about: urban or human interactions, other biotic interactions, etc.
  The mahalanobis model had a similarly high AUC (0.92), indicating a pretty good fit of the model to the data.
  I think that the variation in the models are something that we see a lot of in biology. I think that the high AUC in both of them could be tempting to someone to include the model as-is. The relatively low values for correlation, though, makes me think that the model could (perhaps) be overfit or have some other diagnistic issue that would warrent more investigation. I would spend more time working to validate the model, and do some sensitivity analyses to see which factors the model is most sensitive to. I would also consider examining whether there are other variables at play that could be impacting the habitat suitability of this species.

QUESTION 6: How might you improve SDMs for the Austral grass tree?
  The first item may be improving resolution. We could increase the resolution and perhaps allow for finer-scale interpretations that could expose nuances lost at the larger scale we are looking at. We could also add in some biotic interactions. Since we're just looking at climate variables, we are not considering things like competition for nutrients, water, or sunlight, nor are we considering grazers that may browse the tree (or its competition). We could work on the quality of the data. These data were recorded by a variety of sources. This could include a wide variety of data quality issues. We censored a lot of observations, which isn't necessarily a bad thing, but confining our search to the highest-quality observations from systematic transects or surveys may improve statistical rigor that we could apply to our interpretations. We could also determine a way to include things such as climate change trends to see if these changes may be affecting distribution, but that may involve time series analyses. Finally, we can attempt some ensemble modeling, incorporating different techniques into our analysis such as the time series approach or machine learning tools, but I am not ready for all of that yet.
